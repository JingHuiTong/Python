{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os, glob\n",
    "import pandas as pd\n",
    "from obspy import UTCDateTime\n",
    "from obspy.taup import TauPyModel\n",
    "model = TauPyModel(model=\"iasp91\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadPKL_manual(evtpath):\n",
    "    Meta_pkl = evtpath + '/Meta_manual.pkl'\n",
    "    Station_data_pkl = evtpath + '/Station_data.pkl'\n",
    "    Split_result_pkl = evtpath + '/Split_results_manual.pkl'\n",
    "    SC_result_pkl = evtpath + '/SC_res_manual.pkl'\n",
    "    RC_result_pkl = evtpath + '/RC_res_manual.pkl'\n",
    "#     pick_pkl = evtpath + '/Pickphase.pkl'\n",
    "    Meta = pickle.load(open(Meta_pkl, \"rb\"))\n",
    "    Station_data = pickle.load(open(Station_data_pkl, \"rb\"))\n",
    "    Split_result = pickle.load(open(Split_result_pkl, \"rb\"))\n",
    "    SC_res = pickle.load(open(SC_result_pkl, \"rb\"))\n",
    "    RC_res = pickle.load(open(RC_result_pkl, \"rb\"))\n",
    "#     Pick = pickle.load(open(pick_pkl, \"rb\"))\n",
    "    return Meta, Station_data, Split_result, SC_res, RC_res\n",
    "def ReadPKL_auto(evtpath):\n",
    "    Meta_pkl = evtpath + '/Meta_data.pkl'\n",
    "    Station_data_pkl = evtpath + '/Station_data.pkl'\n",
    "    Split_result_pkl = evtpath + '/Split_results_auto.pkl'\n",
    "    SC_result_pkl = evtpath + '/SC_res.pkl'\n",
    "    RC_result_pkl = evtpath + '/RC_res.pkl'\n",
    "    Meta = pickle.load(open(Meta_pkl, \"rb\"))\n",
    "    Station_data = pickle.load(open(Station_data_pkl, \"rb\"))\n",
    "    Split_result = pickle.load(open(Split_result_pkl, \"rb\"))\n",
    "    SC_res = pickle.load(open(SC_result_pkl, \"rb\"))\n",
    "    RC_res = pickle.load(open(RC_result_pkl, \"rb\"))\n",
    "    return Meta, Station_data, Split_result, SC_res, RC_res\n",
    "def Creatdf():\n",
    "    file = {'station':[],'Baz':[],'Inc':[],'Event':[],'Ev_lat':[],'Ev_lon':[], 'Depth':[],'Mag':[],'Phase':[],\n",
    "            'SCPhi':[],'SCPhi_std':[],'SCdt':[],'SCdt_std':[],\n",
    "            'RCPhi':[],'RCPhi_std':[],'RCdt':[],'RCdt_std':[],\n",
    "            'SNRQ':[],'SNRT':[],'Null':[],'Quality':[],'CpH':[],'Pick':[]}\n",
    "    return file\n",
    "def Append(df,baz,inc,ev_lat,ev_lon,dep,mag,phase,\n",
    "           SCphi,SCphi_std,SCdt,SCdt_std, RCphi,RCphi_std,RCdt,RCdt_std,\n",
    "           snrq,snrt,null,quality,CpH,pick=True):\n",
    "    df['Baz'].append(baz)\n",
    "    df['Inc'].append(inc)\n",
    "    df['Ev_lat'].append(ev_lat)\n",
    "    df['Ev_lon'].append(ev_lon)\n",
    "    df['Depth'].append(dep)\n",
    "    df['Mag'].append(mag)\n",
    "    df['Phase'].append(phase)\n",
    "    df['SCPhi'].append(SCphi)\n",
    "    df['SCPhi_std'].append(SCphi_std)\n",
    "    df['SCdt'].append(SCdt)\n",
    "    df['SCdt_std'].append(SCdt_std)\n",
    "    df['RCPhi'].append(RCphi)\n",
    "    df['RCPhi_std'].append(RCphi_std)\n",
    "    df['RCdt'].append(RCdt)\n",
    "    df['RCdt_std'].append(RCdt_std)\n",
    "    df['SNRQ'].append(snrq)\n",
    "    df['SNRT'].append(snrt)\n",
    "    df['Null'].append(null)\n",
    "    df['Quality'].append(quality)\n",
    "    df['CpH'].append(CpH)\n",
    "    df['Pick'].append(pick)\n",
    "def Calc_rho(RCdt, SCdt):\n",
    "    rho = RCdt/SCdt \n",
    "    return rho\n",
    "def Calc_Phi(RCPhi, SCPhi):\n",
    "    Phi = max (abs(RCPhi-SCPhi), abs(SCPhi-RCPhi))\n",
    "    if Phi > 90: Phi = 180 - Phi\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATApath = '/Volumes/home/Research/STEP/01_Split'\n",
    "SAVEpath = '/Volumes/home/Research/STEP/07_stereoplot_matlab/sws_tools/01_stereoplots/00_data'\n",
    "Path = '/Volumes/home/Research/STEP/02_Station_result_csv'\n",
    "phase='SKS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/pnngww1n0q31w2plgbk53rc00000gn/T/ipykernel_18608/2447487429.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[df['Phase']==phase][df['SNRQ']>=5][df['Pick']==True]\n"
     ]
    }
   ],
   "source": [
    "for STApath in glob.glob(f'{DATApath}/KO*.pkl'):\n",
    "    STApkl = pickle.load(open(STApath, \"rb\"))\n",
    "    values = [value for keys, value in STApkl.items() ][0]\n",
    "    \n",
    "    NET = values['network']; STA = values['station']\n",
    "\n",
    "    newdf = pd.DataFrame()\n",
    "    Splitfile = Creatdf()\n",
    "    Nullfile = Creatdf()\n",
    "    for CSVpath in sorted(glob.glob(f'{Path}/*_SKS_KO/*{NET}*{STA}*.csv')):\n",
    "        df = pd.read_csv(CSVpath)\n",
    "        df = df[df['Phase']==phase][df['SNRQ']>=5][df['Pick']==True]\n",
    "        newdf = newdf.append(df)\n",
    "\n",
    "    for i in range(len(newdf)):\n",
    "        Event = newdf['Event'].values[i]\n",
    "        RCPhi = newdf['RCPhi'].values[i]\n",
    "        RCdt  = newdf['RCdt'].values[i]\n",
    "        SCPhi = newdf['SCPhi'].values[i]\n",
    "        SCdt  = newdf['SCdt'].values[i]\n",
    "        CpH   = newdf['CpH'].values[i]\n",
    "\n",
    "        rho = Calc_rho(RCdt, SCdt)\n",
    "        phi = Calc_Phi(RCPhi, SCPhi)\n",
    "        if 25 < phi < 68 or CpH  > 0.76 :\n",
    "            if CpH  >=0.9 : NULL='True'; quality='good'\n",
    "            else: NULL='True'; quality='fair'\n",
    "        elif 0.8 < rho < 1.1 and phi < 8: NULL='False'; quality='good'\n",
    "        elif 0.7 <= rho < 1.2 and phi <= 25: NULL='False'; quality='fair'\n",
    "        else: NULL='True'; quality='poor'\n",
    "\n",
    "        meta = pickle.load(open(glob.glob(f'{DATApath}/DATA_SKS*/{NET}.{STA}/{Event}/Meta_manual.pkl')[0], \"rb\"))\n",
    "        arrivals = model.get_travel_times(source_depth_in_km=meta.dep,\n",
    "                    distance_in_degree=meta.gac,phase_list=['SKS'])\n",
    "        inc = round(arrivals[0].incident_angle,2)  \n",
    "    \n",
    "        if NULL == 'False':\n",
    "                Append(Splitfile,round(meta.baz,2),inc,meta.lat,meta.lon,meta.dep,meta.mag,meta.phase,\n",
    "                SCPhi,newdf['SCPhi_std'].values[i],SCdt,newdf['SCdt_std'].values[i],\n",
    "                RCPhi,newdf['RCPhi_std'].values[i],RCdt,newdf['RCdt_std'].values[i],\n",
    "                newdf['SNRQ'].values[i], newdf['SNRT'].values[i],NULL,quality,CpH,pick=True)\n",
    "                Splitfile['Event'].append(Event)\n",
    "                Splitfile['station'].append(f'{NET}.{STA}')\n",
    "        elif NULL == 'True':\n",
    "                Append(Nullfile,round(meta.baz,2),inc,meta.lat,meta.lon,meta.dep,meta.mag,meta.phase,\n",
    "                SCPhi,newdf['SCPhi_std'].values[i],SCdt,newdf['SCdt_std'].values[i],\n",
    "                RCPhi,newdf['RCPhi_std'].values[i],RCdt,newdf['RCdt_std'].values[i],\n",
    "                newdf['SNRQ'].values[i], newdf['SNRT'].values[i],NULL,quality,CpH,pick=True)  \n",
    "                Nullfile['Event'].append(Event)    \n",
    "                Nullfile['station'].append(f'{NET}.{STA}')    \n",
    "        \n",
    "    filename = f'{SAVEpath}/splitresults_{NET}.{STA}.csv'\n",
    "    df = pd.DataFrame(Splitfile)\n",
    "    df.to_csv(filename,index=False)\n",
    "    filename = f'{SAVEpath}/splitresultsNULL_{NET}.{STA}.csv'\n",
    "    df = pd.DataFrame(Nullfile)\n",
    "    df.to_csv(filename,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNI\n"
     ]
    }
   ],
   "source": [
    "for STApath in sorted(glob.glob(f'{DATApath}/IU*.pkl')):\n",
    "    STApkl = pickle.load(open(STApath, \"rb\"))\n",
    "    values = [value for keys, value in STApkl.items() ][0]\n",
    "    \n",
    "    NET = values['network']; STA = values['station']\n",
    "    print(STA)\n",
    "    Splitfile = Creatdf()\n",
    "    Nullfile = Creatdf()\n",
    "    for Phase in ['SKS']:\n",
    "        for PHASEpath in sorted(glob.glob(f'{DATApath}/DATA_{Phase}_Mw*/{NET}.{STA}')):\n",
    "            for EVTpath in sorted(glob.glob(f'{PHASEpath}/*')):\n",
    "                EVT = EVTpath.rsplit('/')[-1]\n",
    "                try: \n",
    "                    try :\n",
    "                        Meta, Station_data, Split_result, SC_res, RC_res= ReadPKL_manual(EVTpath)\n",
    "    #                     print('manual')\n",
    "                        rho = Calc_rho(RC_res.dtt, SC_res.dtt)\n",
    "                        phi = Calc_Phi(RC_res.phi, SC_res.phi)\n",
    "                        if 25 < phi < 68 or Meta.CpH > 0.76 :\n",
    "                            if Meta.CpH >=0.9 : NULL='True'; quality='good'\n",
    "                            else: NULL='True'; quality='fair'\n",
    "                        elif 0.8 < rho < 1.1 and phi < 8: NULL='False'; quality='good'\n",
    "                        elif 0.7 <= rho < 1.2 and phi <= 25: NULL='False'; quality='fair'\n",
    "                        else: NULL='True'; quality='poor'\n",
    "                        arrivals = model.get_travel_times(source_depth_in_km=Meta.dep,\n",
    "                                  distance_in_degree=Meta.gac,phase_list=['SKS'])\n",
    "                        inc = round(arrivals[0].incident_angle,2)\n",
    "                        if NULL == 'False':\n",
    "                             Append(Splitfile,round(Meta.baz,2),inc,Meta.lat,Meta.lon,Meta.dep,Meta.mag,Meta.phase,\n",
    "                                round(SC_res.phi,2),round(SC_res.ephi,2),round(SC_res.dtt,2),round(SC_res.edtt,2),\n",
    "                                round(RC_res.phi,2),round(RC_res.ephi,2),round(RC_res.dtt,2),round(RC_res.edtt,2),\n",
    "                                round(Meta.snrq,2), round(Meta.snrt,2),NULL,quality,round(Meta.CpH,2),pick=True)\n",
    "                            Splitfile['Event'].append(EVT)\n",
    "                            Splitfile['station'].append(f'{NET}.{STA}')\n",
    "                        elif NULL == 'True':\n",
    "                             Append(Nullfile,round(Meta.baz,2),inc,Meta.lat,Meta.lon,Meta.dep,Meta.mag,Meta.phase,\n",
    "                                round(SC_res.phi,2),round(SC_res.ephi,2),round(SC_res.dtt,2),round(SC_res.edtt,2),\n",
    "                                round(RC_res.phi,2),round(RC_res.ephi,2),round(RC_res.dtt,2),round(RC_res.edtt,2),\n",
    "                                round(Meta.snrq,2), round(Meta.snrt,2),NULL,quality,round(Meta.CpH,2),pick=True)    \n",
    "                            Nullfile['Event'].append(EVT)    \n",
    "                            Nullfile['station'].append(f'{NET}.{STA}')                   \n",
    "                    except:\n",
    "                        pass\n",
    "                except: print('============'+STA+EVT+'error ============')\n",
    "    # filename = f'{SAVEpath}/splitresults_{NET}.{STA}.csv'\n",
    "    # df = pd.DataFrame(Splitfile)\n",
    "    # df.to_csv(filename,index=False)\n",
    "    # filename = f'{SAVEpath}/splitresultsNULL_{NET}.{STA}.csv'\n",
    "    # df = pd.DataFrame(Nullfile)\n",
    "    # df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c7fae736fe20b15c24d2eb785ff40b610e0707db5318a1e0b0a0a10fe7a5c5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
